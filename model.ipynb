{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:9: DtypeWarning: Columns (23,24,36,49,50,52,53,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master = pd.read_csv('master1.csv')\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data['conditions'] = final_data['conditions'].str.split(',').apply(lambda x: [c.strip() for c in x])\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.drop(columns=['conditions'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "master = pd.read_csv('master1.csv')\n",
    "\n",
    "master = master[master['Primary Type'].isin(['HOMICIDE', 'BATTERY', 'ASSAULT', 'ROBBERY', 'CRIMINAL SEXUAL ASSAULT'])]\n",
    "\n",
    "columns_drop = ['Case Number', 'Time', 'Block', 'IUCR', 'Primary Type', 'Description', 'Location Description', 'Arrest', 'Domestic','Beat','District','Ward','Community Area','FBI Code','X Coordinate',\n",
    "                'Y Coordinate','Updated On','Latitude','Longitude','Location', 'Holiday Day of Week','precipprob','snowdepth','preciptype', 'windgust','winddir',\n",
    "                'solarenergy','sunrise', 'sunset','moonphase', 'description', 'icon','stations']\n",
    "data = master.drop(columns=columns_drop)\n",
    "\n",
    "# Replace NaN values with 0 indicating no holiday and severe risk\n",
    "data['Holiday'] = data['Holiday'].fillna(0)\n",
    "data['severerisk'] = data['severerisk'].fillna(0)\n",
    "\n",
    "# Replace non-NaN values with 1 indicating a holiday\n",
    "data.loc[data['Holiday'] != 0, 'Holiday'] = 1\n",
    "\n",
    "# Optionally, convert the 'Holiday' column to integer type\n",
    "data['Holiday'] = data['Holiday'].astype(int)\n",
    "\n",
    "# drop dates before 2010 as weather does not have that data\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%y')\n",
    "data= data[data['Date'].dt.year >= 2010]\n",
    "\n",
    "daily_counts = data.groupby('Date').size().reset_index(name='Crime_Count')\n",
    "\n",
    "# Merge daily_counts with the original DataFrame\n",
    "merged_data = pd.merge(data, daily_counts, on='Date')\n",
    "\n",
    "# Drop duplicate rows to keep only one entry per day\n",
    "final_data = merged_data.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "final_data.head()\n",
    "\n",
    "final_data['conditions'] = final_data['conditions'].str.split(',').apply(lambda x: [c.strip() for c in x])\n",
    "\n",
    "# Get the set of all unique conditions\n",
    "unique_conditions = set(condition for sublist in final_data['conditions'] for condition in sublist)\n",
    "\n",
    "# Create dummy variables for each unique condition\n",
    "for condition in unique_conditions:\n",
    "    final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
    "\n",
    "# Drop the original 'Conditions' column\n",
    "final_data.drop(columns=['conditions'], inplace=True)\n",
    "\n",
    "final_data.to_csv('test.csv', index=False)\n",
    "\n",
    "X = final_data.drop(columns=['Crime_Count', 'ID', 'Date'])\n",
    "\n",
    "# Extract the target variable\n",
    "y = final_data['Crime_Count']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "Best Parameters: {'learning_rate': 0.02, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Best Mean Squared Error: 20.489016218342503\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.015, 0.02, 0.025],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [200, 250, 300],\n",
    "    'subsample': [0.6, 0.7, 0.8],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Mean Cross-Validated Mean Squared Error: 20.508155951070343\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.1),  # Continuous uniform distribution\n",
    "    'max_depth': randint(3, 10),           # Discrete uniform distribution\n",
    "    'n_estimators': randint(100, 500),     # Discrete uniform distribution\n",
    "    'subsample': uniform(0.5, 0.5),        # Continuous uniform distribution\n",
    "    'colsample_bytree': uniform(0.5, 0.5), # Continuous uniform distribution\n",
    "    'gamma': uniform(0, 0.5),              # Continuous uniform distribution\n",
    "}\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "mse_scores = []\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Perform random search cross-validation\n",
    "    xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=100,\n",
    "                                    scoring='neg_mean_squared_error', cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "    xgb_random.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Get the best model from the random search\n",
    "    xgb_best_model = xgb_random.best_estimator_\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    xgb_predictions = xgb_best_model.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_val_fold, xgb_predictions)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the mean MSE across all folds\n",
    "mean_mse = np.mean(mse_scores)\n",
    "print(\"Mean Cross-Validated Mean Squared Error:\", mean_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.2658636299437305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "xgb_best_model = xgb_random.best_estimator_\n",
    "xgb_predictions = xgb_best_model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, xgb_predictions)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
