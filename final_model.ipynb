{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:9: DtypeWarning: Columns (23,24,36,49,50,52,53,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master = pd.read_csv('master1.csv')\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data['conditions'] = final_data['conditions'].str.split(',').apply(lambda x: [c.strip() for c in x])\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_15316\\4265478778.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.drop(columns=['conditions'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "master = pd.read_csv('master1.csv')\n",
    "\n",
    "master = master[master['Primary Type'].isin(['HOMICIDE', 'BATTERY', 'ASSAULT', 'ROBBERY', 'CRIMINAL SEXUAL ASSAULT'])]\n",
    "\n",
    "columns_drop = ['Case Number', 'Time', 'Block', 'IUCR', 'Primary Type', 'Description', 'Location Description', 'Arrest', 'Domestic','Beat','District','Ward','Community Area','FBI Code','X Coordinate',\n",
    "                'Y Coordinate','Updated On','Latitude','Longitude','Location', 'Holiday Day of Week','precipprob','snowdepth','preciptype', 'windgust','winddir',\n",
    "                'solarenergy','sunrise', 'sunset','moonphase', 'description', 'icon','stations']\n",
    "data = master.drop(columns=columns_drop)\n",
    "\n",
    "# Replace NaN values with 0 indicating no holiday and severe risk\n",
    "data['Holiday'] = data['Holiday'].fillna(0)\n",
    "data['severerisk'] = data['severerisk'].fillna(0)\n",
    "\n",
    "# Replace non-NaN values with 1 indicating a holiday\n",
    "data.loc[data['Holiday'] != 0, 'Holiday'] = 1\n",
    "\n",
    "# Optionally, convert the 'Holiday' column to integer type\n",
    "data['Holiday'] = data['Holiday'].astype(int)\n",
    "\n",
    "# drop dates before 2010 as weather does not have that data\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%y')\n",
    "data= data[data['Date'].dt.year >= 2010]\n",
    "\n",
    "daily_counts = data.groupby('Date').size().reset_index(name='Crime_Count')\n",
    "\n",
    "# Merge daily_counts with the original DataFrame\n",
    "merged_data = pd.merge(data, daily_counts, on='Date')\n",
    "\n",
    "# Drop duplicate rows to keep only one entry per day\n",
    "final_data = merged_data.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "final_data.head()\n",
    "\n",
    "final_data['conditions'] = final_data['conditions'].str.split(',').apply(lambda x: [c.strip() for c in x])\n",
    "\n",
    "# Get the set of all unique conditions\n",
    "unique_conditions = set(condition for sublist in final_data['conditions'] for condition in sublist)\n",
    "\n",
    "# Create dummy variables for each unique condition\n",
    "for condition in unique_conditions:\n",
    "    final_data.loc[:, condition] = final_data['conditions'].apply(lambda x: 1 if condition in x else 0)\n",
    "\n",
    "# Drop the original 'Conditions' column\n",
    "final_data.drop(columns=['conditions'], inplace=True)\n",
    "\n",
    "final_data.to_csv('test.csv', index=False)\n",
    "\n",
    "X = final_data.drop(columns=['Crime_Count', 'ID', 'Date'])\n",
    "\n",
    "# Extract the target variable\n",
    "y = final_data['Crime_Count']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            Crime_Count   R-squared:                       0.240\n",
      "Model:                            OLS   Adj. R-squared:                  0.235\n",
      "Method:                 Least Squares   F-statistic:                     47.92\n",
      "Date:                Tue, 26 Mar 2024   Prob (F-statistic):          1.64e-220\n",
      "Time:                        16:17:59   Log-Likelihood:                -12091.\n",
      "No. Observations:                4134   AIC:                         2.424e+04\n",
      "Df Residuals:                    4106   BIC:                         2.441e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================================\n",
      "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "const                             31.7820     15.407      2.063      0.039       1.575      61.989\n",
      "FullMoon                          -0.7541      0.379     -1.991      0.047      -1.497      -0.011\n",
      "Holiday                            0.3346      0.370      0.905      0.365      -0.390       1.059\n",
      "tempmax                            0.0478      0.109      0.438      0.662      -0.166       0.262\n",
      "tempmin                            0.0186      0.119      0.157      0.875      -0.214       0.251\n",
      "temp                              -0.1301      0.278     -0.468      0.639      -0.675       0.414\n",
      "feelslikemax                      -0.0237      0.079     -0.300      0.764      -0.179       0.131\n",
      "feelslikemin                      -0.0807      0.093     -0.870      0.384      -0.263       0.101\n",
      "feelslike                          0.2608      0.156      1.677      0.094      -0.044       0.566\n",
      "dew                                0.0330      0.186      0.177      0.860      -0.333       0.399\n",
      "humidity                           0.0065      0.049      0.134      0.893      -0.089       0.102\n",
      "precip                            -0.0385      0.015     -2.482      0.013      -0.069      -0.008\n",
      "precipcover                       -0.0081      0.008     -1.001      0.317      -0.024       0.008\n",
      "snow                              -0.2031      0.124     -1.633      0.103      -0.447       0.041\n",
      "windspeed                         -0.0110      0.012     -0.906      0.365      -0.035       0.013\n",
      "sealevelpressure                  -0.0182      0.013     -1.354      0.176      -0.044       0.008\n",
      "cloudcover                         0.0094      0.005      1.840      0.066      -0.001       0.019\n",
      "visibility                        -0.0053      0.055     -0.098      0.922      -0.113       0.102\n",
      "solarradiation                     0.0155      0.002      7.739      0.000       0.012       0.019\n",
      "uvindex                           -0.1874      0.074     -2.542      0.011      -0.332      -0.043\n",
      "severerisk                        -0.0834      0.011     -7.677      0.000      -0.105      -0.062\n",
      "Rain                               0.0115      0.219      0.052      0.958      -0.418       0.440\n",
      "Clear                              0.3852      2.065      0.187      0.852      -3.664       4.434\n",
      "Freezing Drizzle/Freezing Rain    -0.8438      2.322     -0.363      0.716      -5.395       3.708\n",
      "Partially cloudy                  -0.1487      2.056     -0.072      0.942      -4.179       3.882\n",
      "Overcast                          -0.2641      2.081     -0.127      0.899      -4.345       3.817\n",
      "Ice                                2.9731      1.908      1.558      0.119      -0.768       6.714\n",
      "Snow                              -0.2787      0.307     -0.909      0.364      -0.880       0.323\n",
      "==============================================================================\n",
      "Omnibus:                      121.811   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              133.666\n",
      "Skew:                           0.413   Prob(JB):                     9.44e-30\n",
      "Kurtosis:                       3.306   Cond. No.                     2.26e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.26e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Mean Squared Error (MSE): 21.90228839102366\n",
      "R^2 Score: 0.2549848977436511\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression model\n",
    "X_train = sm.add_constant(X_train)  # Add constant to X_train\n",
    "model = sm.OLS(y_train, X_train)    # Create model\n",
    "results = model.fit()               # Fit model\n",
    "print(results.summary())\n",
    "\n",
    "# Make predictions on the test set\n",
    "X_test = sm.add_constant(X_test)  # Add constant to X_test\n",
    "y_pred = results.predict(X_test)  # Predict using the fitted model\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.015, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=250, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=2, n_estimators=300, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.7; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=250, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=250, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.025, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "Best Parameters: {'learning_rate': 0.02, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Best Mean Squared Error: 20.489016218342503\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.015, 0.02, 0.025],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [200, 250, 300],\n",
    "    'subsample': [0.6, 0.7, 0.8],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Mean Cross-Validated Mean Squared Error: 20.508155951070343\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.1),  # Continuous uniform distribution\n",
    "    'max_depth': randint(3, 10),           # Discrete uniform distribution\n",
    "    'n_estimators': randint(100, 500),     # Discrete uniform distribution\n",
    "    'subsample': uniform(0.5, 0.5),        # Continuous uniform distribution\n",
    "    'colsample_bytree': uniform(0.5, 0.5), # Continuous uniform distribution\n",
    "    'gamma': uniform(0, 0.5),              # Continuous uniform distribution\n",
    "}\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "mse_scores = []\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Perform random search cross-validation\n",
    "    xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=100,\n",
    "                                    scoring='neg_mean_squared_error', cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "    xgb_random.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Get the best model from the random search\n",
    "    xgb_best_model = xgb_random.best_estimator_\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    xgb_predictions = xgb_best_model.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_val_fold, xgb_predictions)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the mean MSE across all folds\n",
    "mean_mse = np.mean(mse_scores)\n",
    "print(\"Mean Cross-Validated Mean Squared Error:\", mean_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.2658636299437305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "xgb_best_model = xgb_random.best_estimator_\n",
    "xgb_predictions = xgb_best_model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, xgb_predictions)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
